# EstÃ¡ndares y Arquitectura de Testing para Rexus.app

## ğŸ¯ Objetivos del Sistema de Testing

### 1. **Cobertura Completa**
- **Unitarios**: LÃ³gica de negocio y funciones individuales
- **IntegraciÃ³n**: InteracciÃ³n entre componentes
- **UI**: Interfaz de usuario y workflows
- **E2E**: Flujos completos de usuario
- **Performance**: Rendimiento y escalabilidad
- **Seguridad**: ValidaciÃ³n de vulnerabilidades

### 2. **Calidad y Mantenibilidad**
- Tests atÃ³micos y determinÃ­sticos
- DocumentaciÃ³n clara y completa
- Fixtures reutilizables
- Mocks apropiados para dependencias externas
- Assertions especÃ­ficas y descriptivas

---

## ğŸ“ Estructura Organizacional

### **Nivel 1: Por Tipo de Test**
```
tests/
â”œâ”€â”€ unit/           # Tests unitarios (lÃ³gica pura)
â”œâ”€â”€ integration/    # Tests de integraciÃ³n 
â”œâ”€â”€ ui/            # Tests de interfaz de usuario
â”œâ”€â”€ e2e/           # Tests end-to-end
â”œâ”€â”€ performance/   # Tests de rendimiento
â”œâ”€â”€ security/      # Tests de seguridad
â””â”€â”€ fixtures/      # Datos y utilidades compartidas
```

### **Nivel 2: Por MÃ³dulo**
```
tests/unit/
â”œâ”€â”€ core/          # Core del sistema (auth, db, etc.)
â”œâ”€â”€ modules/       # MÃ³dulos de negocio
â”‚   â”œâ”€â”€ inventario/
â”‚   â”œâ”€â”€ obras/
â”‚   â”œâ”€â”€ logistica/
â”‚   â”œâ”€â”€ usuarios/
â”‚   â”œâ”€â”€ administracion/
â”‚   â””â”€â”€ ...
â””â”€â”€ utils/         # Utilidades y helpers
```

### **Nivel 3: Por Componente**
```
tests/unit/modules/inventario/
â”œâ”€â”€ test_model.py      # Tests del modelo
â”œâ”€â”€ test_view.py       # Tests de la vista
â”œâ”€â”€ test_controller.py # Tests del controlador
â””â”€â”€ test_utils.py      # Tests de utilidades especÃ­ficas
```

---

## ğŸ—ï¸ Arquitectura de Tests

### **Nomenclatura EstÃ¡ndar**
- **Archivos**: `test_[componente].py`
- **Clases**: `Test[ComponenteName]`
- **MÃ©todos**: `test_[accion]_[escenario]_[resultado_esperado]`

**Ejemplos:**
```python
def test_crear_producto_con_datos_validos_retorna_exito()
def test_crear_producto_con_codigo_duplicado_retorna_error()
def test_buscar_productos_sin_filtros_retorna_todos()
```

### **Estructura de Test Individual**
```python
def test_nombre_descriptivo():
    """
    DescripciÃ³n del test:
    - QuÃ© funcionalidad se estÃ¡ probando
    - QuÃ© escenario especÃ­fico
    - QuÃ© resultado se espera
    """
    # ARRANGE: Preparar datos y estado inicial
    datos = {"codigo": "PROD001", "nombre": "Test"}
    
    # ACT: Ejecutar la acciÃ³n
    resultado = modelo.crear_producto(datos)
    
    # ASSERT: Verificar el resultado
    assert resultado.exito is True
    assert resultado.mensaje == "Producto creado exitosamente"
```

---

## ğŸ“‹ Checklist de Calidad de Tests

### âœ… **Criterios Obligatorios**

#### **1. Funcionalidad**
- [ ] El test verifica una funcionalidad especÃ­fica
- [ ] Cubre casos positivos y negativos
- [ ] Incluye validaciÃ³n de edge cases
- [ ] Maneja excepciones apropiadamente

#### **2. Independencia**
- [ ] No depende de otros tests
- [ ] No modifica estado global permanente
- [ ] Usa fixtures para datos de prueba
- [ ] Se puede ejecutar en cualquier orden

#### **3. Determinismo**
- [ ] Produce el mismo resultado en cada ejecuciÃ³n
- [ ] No depende de factores externos variables
- [ ] Usa mocks para servicios externos
- [ ] Controla el tiempo y aleatoriedad

#### **4. Velocidad**
- [ ] Se ejecuta rÃ¡pidamente (< 1 segundo unitarios)
- [ ] Minimiza I/O y operaciones costosas
- [ ] Usa mocks para bases de datos
- [ ] Evita sleeps y waits innecesarios

#### **5. Legibilidad**
- [ ] Nombre descriptivo y claro
- [ ] DocumentaciÃ³n explicativa
- [ ] Estructura AAA (Arrange-Act-Assert)
- [ ] Assertions especÃ­ficas y descriptivas

#### **6. Mantenibilidad**
- [ ] Usa fixtures reutilizables
- [ ] Evita duplicaciÃ³n de cÃ³digo
- [ ] Sigue convenciones del proyecto
- [ ] Es fÃ¡cil de modificar y extender

---

## ğŸ¨ Patrones y Mejores PrÃ¡cticas

### **1. Fixtures EstratÃ©gicas**
```python
@pytest.fixture(scope="function")
def producto_valido():
    """Producto con datos vÃ¡lidos para tests."""
    return {
        'codigo': 'PROD001',
        'nombre': 'Producto Test',
        'precio': 100.00
    }

@pytest.fixture(scope="function") 
def modelo_con_mock_db(mock_db):
    """Modelo de inventario con base de datos mockeada."""
    return InventarioModel(mock_db)
```

### **2. Tests Parametrizados**
```python
@pytest.mark.parametrize("codigo,nombre,esperado", [
    ("", "Producto", False),           # CÃ³digo vacÃ­o
    ("PROD001", "", False),            # Nombre vacÃ­o  
    ("PROD001", "Producto", True),     # Datos vÃ¡lidos
])
def test_validar_producto(codigo, nombre, esperado):
    resultado = validar_producto(codigo, nombre)
    assert resultado == esperado
```

### **3. Mocks EspecÃ­ficos**
```python
def test_crear_producto_error_db(modelo_con_mock_db):
    # Simular error de base de datos
    modelo_con_mock_db.db.cursor().execute.side_effect = Exception("Error DB")
    
    resultado = modelo_con_mock_db.crear_producto({"codigo": "PROD001"})
    
    assert resultado.exito is False
    assert "Error DB" in resultado.mensaje
```

### **4. Tests de UI**
```python
def test_boton_guardar_habilita_con_datos_validos(qapp):
    """Test que el botÃ³n se habilita con datos vÃ¡lidos."""
    dialog = ProductoDialog()
    
    # Llenar campos con datos vÃ¡lidos
    dialog.input_codigo.setText("PROD001")
    dialog.input_nombre.setText("Producto Test")
    
    # Verificar que el botÃ³n se habilitÃ³
    assert dialog.btn_guardar.isEnabled() is True
```

---

## ğŸ“Š MÃ©tricas y Reportes

### **Cobertura MÃ­nima por Tipo**
- **Unitarios**: 90%+ de cobertura de cÃ³digo
- **IntegraciÃ³n**: 80%+ de flujos principales
- **UI**: 70%+ de componentes crÃ­ticos
- **E2E**: 100% de workflows principales

### **Criterios de AceptaciÃ³n**
- âœ… Todos los tests pasan
- âœ… Cobertura >= 85% total
- âœ… No hay tests skipeados sin justificaciÃ³n
- âœ… Tiempo total < 5 minutos para suite completa
- âœ… No hay warnings o deprecations

---

## ğŸ”§ Herramientas y ConfiguraciÃ³n

### **pytest.ini**
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --tb=short --strict-markers
markers =
    unit: Tests unitarios
    integration: Tests de integraciÃ³n  
    ui: Tests de interfaz de usuario
    slow: Tests que toman mÃ¡s tiempo
    skip_ci: Tests que se saltan en CI
```

### **Comandos Ãštiles**
```bash
# Ejecutar todos los tests
pytest

# Solo tests unitarios
pytest -m unit

# Con cobertura
pytest --cov=rexus --cov-report=html

# Tests especÃ­ficos
pytest tests/unit/modules/inventario/

# Con profiling
pytest --profile
```

---

## ğŸ“ DocumentaciÃ³n de Tests

Cada archivo de test debe incluir:

```python
"""
Tests para [Componente/MÃ³dulo]

DescripciÃ³n:
    Tests que validan [funcionalidad principal]

Scope:
    - Funcionalidades cubiertas
    - Edge cases considerados
    - Limitaciones conocidas

Dependencies:
    - Fixtures requeridas
    - Mocks utilizados
    - ConfiguraciÃ³n especial

Author: [Nombre]
Date: [Fecha]
Version: [Version]
"""
```

---

Esta arquitectura asegura tests robustos, mantenibles y que agreguen valor real al desarrollo del sistema Rexus.app.
