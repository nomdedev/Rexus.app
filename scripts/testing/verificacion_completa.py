#!/usr/bin/env python3
"""
VerificaciÃ³n Completa del Proyecto
=================================

Este script ejecuta una verificaciÃ³n integral del proyecto, compilando todos
los anÃ¡lisis, mejoras y checklists generados para crear un informe final de estado.

Funcionalidades:
- Ejecuta todos los scripts de anÃ¡lisis y verificaciÃ³n
- Recopila resultados de tests y cobertura
- Genera informe final con recomendaciones
- Verifica cumplimiento de estÃ¡ndares de seguridad y UX
- Proporciona roadmap de mejoras pendientes

Autor: Sistema de VerificaciÃ³n Integral
Fecha: 2025-06-25
"""

class VerificadorCompleto:
    """Ejecuta verificaciÃ³n completa del proyecto."""

    def __init__(self, proyecto_root: str):
        self.proyecto_root = Path(proyecto_root)
        self.informes_dir = self.proyecto_root / "informes_modulos"
        self.checklists_dir = self.proyecto_root / "docs" / "checklists_completados"
        self.tests_dir = self.proyecto_root / "tests"
        self.scripts_dir = self.proyecto_root / "scripts" / "verificacion"

        self.estado_global = {
            'fecha_verificacion': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'modulos_analizados': 0,
            'tests_ejecutados': 0,
            'tests_pasaron': 0,
            'cobertura_promedio': 0,
            'errores_criticos': [],
            'advertencias': [],
            'mejoras_sugeridas': [],
            'puntuacion_global': 0
        }

    def ejecutar_verificacion_completa(self):
        """Ejecuta todos los pasos de verificaciÃ³n del proyecto."""
        print("ğŸ” VERIFICACIÃ“N COMPLETA DEL PROYECTO")
        print("=" * 50)

        # 1. Verificar estructura del proyecto
        print("\\nğŸ“ 1. Verificando estructura del proyecto...")
        self._verificar_estructura_proyecto()

        # 2. Ejecutar anÃ¡lisis de mÃ³dulos
        print("\\nğŸ”¬ 2. Ejecutando anÃ¡lisis de mÃ³dulos...")
        self._ejecutar_analisis_modulos()

        # 3. Ejecutar tests
        print("\\nğŸ§ª 3. Ejecutando tests...")
        self._ejecutar_tests()

        # 4. Verificar seguridad
        print("\\nğŸ”’ 4. Verificando seguridad...")
        self._verificar_seguridad()

        # 5. Verificar feedback visual
        print("\\nğŸ¨ 5. Verificando feedback visual...")
        self._verificar_feedback_visual()

        # 6. Compilar checklists
        print("\\nğŸ“‹ 6. Compilando checklists...")
        self._compilar_checklists()

        # 7. Calcular puntuaciÃ³n global
        print("\\nğŸ“Š 7. Calculando puntuaciÃ³n global...")
        self._calcular_puntuacion_global()

        # 8. Generar informe final
        print("\\nğŸ“„ 8. Generando informe final...")
        self._generar_informe_final()

        print("\\nâœ… VerificaciÃ³n completa terminada")
        print(f"ğŸ“„ Ver informe final en: informe_estado_proyecto.md")

    def _verificar_estructura_proyecto(self):
        """Verifica la estructura bÃ¡sica del proyecto."""
        estructura_requerida = [
            "modules",
            "tests",
            "docs",
            "core",
            "utils",
            "scripts",
            "requirements.txt",
            "README.md"
        ]

        faltantes = []
        for item in estructura_requerida:
            if not (self.proyecto_root / item).exists():
                faltantes.append(item)

        if faltantes:
            self.estado_global['errores_criticos'].append(
                f"Estructura incompleta: faltan {', '.join(faltantes)}"
            )
        else:
            print("âœ… Estructura del proyecto completa")

    def _ejecutar_analisis_modulos(self):
        """Ejecuta el anÃ¡lisis automÃ¡tico de mÃ³dulos."""
        try:
            # Verificar si ya existe anÃ¡lisis reciente
            if self.informes_dir.exists():
                informes = list(self.informes_dir.glob("analisis_*.json"))
                self.estado_global['modulos_analizados'] = len(informes)
                print(f"âœ… {len(informes)} mÃ³dulos analizados")

                # Revisar informes para extraer mÃ©tricas
                for informe_file in informes:
                    try:
                        with open(informe_file, 'r', encoding='utf-8') as f:
                            datos = json.load(f)

                        # Verificar si hay sugerencias crÃ­ticas
                        if 'sugerencias' in datos:
                            for sugerencia in datos['sugerencias']:
                                if sugerencia.get('prioridad') == 'alta':
                                    self.estado_global['errores_criticos'].append(
                                        f"{datos.get('nombre', 'mÃ³dulo')}: {sugerencia.get('descripcion', 'Error sin descripciÃ³n')}"
                                    )
                    except Exception as e:
                        print(f"âš ï¸ Error leyendo {informe_file}: {e}")
            else:
                print("âš ï¸ No se encontraron anÃ¡lisis de mÃ³dulos")
                self.estado_global['advertencias'].append("AnÃ¡lisis de mÃ³dulos no ejecutado")

        except Exception as e:
            print(f"âŒ Error en anÃ¡lisis de mÃ³dulos: {e}")
            self.estado_global['errores_criticos'].append(f"Error en anÃ¡lisis de mÃ³dulos: {e}")

    def _ejecutar_tests(self):
        """Ejecuta los tests del proyecto."""
        try:
            # Ejecutar pytest con coverage
            cmd = [sys.executable, "-m", "pytest", str(self.tests_dir), "-v", "--tb=short"]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=str(self.proyecto_root),
                timeout=300  # 5 minutos mÃ¡ximo
            )

            # Parsear resultados
            output = result.stdout + result.stderr

            # Contar tests
            if "passed" in output:
                match = re.search(r'(\\d+) passed', output)
                if match:
                    self.estado_global['tests_pasaron'] = int(match.group(1))

            if "failed" in output:
                match = re.search(r'(\\d+) failed', output)
                if match:
                    tests_fallaron = int(match.group(1))
                    self.estado_global['errores_criticos'].append(
                        f"{tests_fallaron} tests fallaron"
                    )

            self.estado_global['tests_ejecutados'] = self.estado_global['tests_pasaron']

            if result.returncode == 0:
                print(f"âœ… Tests ejecutados: {self.estado_global['tests_pasaron']} pasaron")
            else:
                print(f"âš ï¸ Algunos tests fallaron. Ver detalles en el log.")

        except subprocess.TimeoutExpired:
            print("âš ï¸ Tests tomaron demasiado tiempo (timeout)")
            self.estado_global['advertencias'].append("Tests timeout")
        except Exception as e:
            print(f"âŒ Error ejecutando tests: {e}")
            self.estado_global['errores_criticos'].append(f"Error ejecutando tests: {e}")

    def _verificar_seguridad(self):
        """Verifica aspectos de seguridad del proyecto."""
        seguridad_ok = True

        # Verificar si existen utilidades de seguridad
        utils_seguridad = [
            "utils/sql_seguro.py",
            "utils/sanitizador_sql.py",
            "utils/validador_http.py"
        ]

        for util in utils_seguridad:
            if not (self.proyecto_root / util).exists():
                seguridad_ok = False
                self.estado_global['advertencias'].append(f"Utilidad de seguridad faltante: {util}")

        # Verificar checklists de seguridad
        checklists_seguridad = [
            "docs/checklists/checklist_implementacion_seguridad.md",
            "docs/checklists/checklist_uso_sql_seguro.md"
        ]

        for checklist in checklists_seguridad:
            if not (self.proyecto_root / checklist).exists():
                self.estado_global['advertencias'].append(f"Checklist de seguridad faltante: {checklist}")

        if seguridad_ok:
            print("âœ… Utilidades de seguridad implementadas")
        else:
            print("âš ï¸ Algunas utilidades de seguridad faltan")

    def _verificar_feedback_visual(self):
        """Verifica el estado del feedback visual."""
        reporte_feedback = self.proyecto_root / "mejoras_feedback_visual.md"

        if reporte_feedback.exists():
            try:
                with open(reporte_feedback, 'r', encoding='utf-8') as f:
                    contenido = f.read()

                # Contar mÃ³dulos mejorados
                if "MÃ³dulos mejorados:" in contenido:
                    matches = re.findall(r'âœ….*\\*\\*(.+?)\\*\\*', contenido)
                    modulos_mejorados = len(matches)
                    print(f"âœ… Feedback visual: {modulos_mejorados} mÃ³dulos mejorados")
                else:
                    print("âš ï¸ No se detectaron mejoras de feedback visual")

            except Exception as e:
                print(f"âš ï¸ Error leyendo reporte de feedback: {e}")
        else:
import json
import os
import re
import subprocess
import sys
from datetime import datetime, timedelta
from pathlib import Path

            print("âš ï¸ VerificaciÃ³n de feedback visual no ejecutada")
            self.estado_global['advertencias'].append("Feedback visual no verificado")

    def _compilar_checklists(self):
        """Compila el estado de los checklists."""
        if self.checklists_dir.exists():
            checklists = list(self.checklists_dir.glob("checklist_completo_*.md"))
            print(f"âœ… {len(checklists)} checklists generados")

            # Sugerir completar verificaciÃ³n manual
            self.estado_global['mejoras_sugeridas'].append(
                f"Completar verificaciÃ³n manual de {len(checklists)} checklists generados"
            )
        else:
            print("âš ï¸ Checklists no generados")
            self.estado_global['advertencias'].append("Checklists no generados")

    def _calcular_puntuacion_global(self):
        """Calcula una puntuaciÃ³n global del proyecto."""
        puntuacion = 100

        # Penalizaciones por errores crÃ­ticos
        puntuacion -= len(self.estado_global['errores_criticos']) * 15

        # Penalizaciones por advertencias
        puntuacion -= len(self.estado_global['advertencias']) * 5

        # Bonus por tests pasando
        if self.estado_global['tests_pasaron'] > 50:
            puntuacion += 10
        elif self.estado_global['tests_pasaron'] > 20:
            puntuacion += 5

        # Bonus por mÃ³dulos analizados
        if self.estado_global['modulos_analizados'] >= 10:
            puntuacion += 10
        elif self.estado_global['modulos_analizados'] >= 5:
            puntuacion += 5

        # Asegurar que estÃ© en rango 0-100
        puntuacion = max(0, min(100, puntuacion))
        self.estado_global['puntuacion_global'] = puntuacion

        # Clasificar estado
        if puntuacion >= 90:
            estado = "ğŸŸ¢ EXCELENTE"
        elif puntuacion >= 75:
            estado = "ğŸŸ¡ BUENO"
        elif puntuacion >= 60:
            estado = "ğŸŸ  REGULAR"
        else:
            estado = "ğŸ”´ NECESITA MEJORAS"

        print(f"ğŸ“Š PuntuaciÃ³n global: {puntuacion}/100 - {estado}")

    def _generar_informe_final(self):
        """Genera el informe final de estado del proyecto."""
        fecha = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Determinar estado general
        if self.estado_global['puntuacion_global'] >= 90:
            estado_emoji = "ğŸŸ¢"
            estado_texto = "EXCELENTE"
            estado_descripcion = "El proyecto cumple con todos los estÃ¡ndares de calidad y seguridad."
        elif self.estado_global['puntuacion_global'] >= 75:
            estado_emoji = "ğŸŸ¡"
            estado_texto = "BUENO"
            estado_descripcion = "El proyecto cumple con la mayorÃ­a de estÃ¡ndares, con mejoras menores pendientes."
        elif self.estado_global['puntuacion_global'] >= 60:
            estado_emoji = "ğŸŸ "
            estado_texto = "REGULAR"
            estado_descripcion = "El proyecto necesita algunas mejoras importantes para cumplir estÃ¡ndares."
        else:
            estado_emoji = "ğŸ”´"
            estado_texto = "NECESITA MEJORAS"
            estado_descripcion = "El proyecto requiere mejoras significativas en mÃºltiples Ã¡reas."

        informe = f"""# Informe Final de Estado del Proyecto

{estado_emoji} **ESTADO GENERAL: {estado_texto}**

**Fecha de verificaciÃ³n:** {fecha}
**PuntuaciÃ³n global:** {self.estado_global['puntuacion_global']}/100

{estado_descripcion}

---

## Resumen Ejecutivo

### MÃ©tricas Clave
- ğŸ“ **MÃ³dulos analizados:** {self.estado_global['modulos_analizados']}
- ğŸ§ª **Tests ejecutados:** {self.estado_global['tests_ejecutados']} (âœ… {self.estado_global['tests_pasaron']} pasaron)
- âŒ **Errores crÃ­ticos:** {len(self.estado_global['errores_criticos'])}
- âš ï¸ **Advertencias:** {len(self.estado_global['advertencias'])}
- ğŸ’¡ **Mejoras sugeridas:** {len(self.estado_global['mejoras_sugeridas'])}

### Estado por Ãrea

| Ãrea | Estado | DescripciÃ³n |
|------|--------|-------------|
| ğŸ“ Estructura | {'âœ… Completo' if len([e for e in self.estado_global['errores_criticos'] if 'Estructura' in e]) == 0 else 'âš ï¸ Incompleto'} | Estructura bÃ¡sica del proyecto |
| ğŸ”¬ AnÃ¡lisis | {'âœ… Completo' if self.estado_global['modulos_analizados'] > 0 else 'âŒ Pendiente'} | AnÃ¡lisis automÃ¡tico de mÃ³dulos |
| ğŸ§ª Tests | {'âœ… Pasando' if self.estado_global['tests_pasaron'] > 0 and len([e for e in self.estado_global['errores_criticos'] if 'tests' in e.lower()]) == 0 else 'âš ï¸ Con errores'} | Suite de tests unitarios |
| ğŸ”’ Seguridad | {'âœ… Implementado' if len([a for a in self.estado_global['advertencias'] if 'seguridad' in a.lower()]) < 2 else 'âš ï¸ Pendiente'} | Utilidades y checklists de seguridad |
| ğŸ¨ UX | {'âœ… Mejorado' if Path(self.proyecto_root / "mejoras_feedback_visual.md").exists() else 'âš ï¸ Pendiente'} | Feedback visual y experiencia de usuario |
| ğŸ“‹ Checklists | {'âœ… Generados' if self.checklists_dir.exists() else 'âŒ Pendientes'} | Checklists de verificaciÃ³n por mÃ³dulo |

---

## Errores CrÃ­ticos

"""

        if self.estado_global['errores_criticos']:
            for i, error in enumerate(self.estado_global['errores_criticos'], 1):
                informe += f"{i}. âŒ **{error}**\\n"
        else:
            informe += "âœ… No se detectaron errores crÃ­ticos.\\n"

        informe += f"""
---

## Advertencias

"""

        if self.estado_global['advertencias']:
            for i, advertencia in enumerate(self.estado_global['advertencias'], 1):
                informe += f"{i}. âš ï¸ {advertencia}\\n"
        else:
            informe += "âœ… No se detectaron advertencias.\\n"

        informe += f"""
---

## Mejoras Sugeridas

"""

        if self.estado_global['mejoras_sugeridas']:
            for i, mejora in enumerate(self.estado_global['mejoras_sugeridas'], 1):
                informe += f"{i}. ğŸ’¡ {mejora}\\n"
        else:
            informe += "âœ… No hay mejoras adicionales sugeridas.\\n"

        informe += f"""
---

## Archivos y Recursos Generados

### AnÃ¡lisis y Reportes
- ğŸ“Š **AnÃ¡lisis de mÃ³dulos:** `informes_modulos/` ({self.estado_global['modulos_analizados']} archivos)
- ğŸ“‹ **Checklists completados:** `docs/checklists_completados/`
- ğŸ¨ **Reporte de feedback visual:** `mejoras_feedback_visual.md`
- ğŸ“„ **Este informe:** `informe_estado_proyecto.md`

### Herramientas y Scripts
- ğŸ”§ **Scripts de verificaciÃ³n:** `scripts/verificacion/`
- ğŸ”’ **Utilidades de seguridad:** `utils/`
- ğŸ“š **DocumentaciÃ³n:** `docs/`
- ğŸ§ª **Tests mejorados:** `tests/`

### Backups
- ğŸ’¾ **Backups de feedback visual:** `backups_feedback/`

---

## Roadmap de PrÃ³ximos Pasos

### Inmediatos (PrÃ³ximos 7 dÃ­as)
1. **Resolver errores crÃ­ticos** identificados en este informe
2. **Completar verificaciones manuales** de los checklists generados
3. **Ejecutar tests** para verificar que todas las mejoras funcionan correctamente

### Corto plazo (PrÃ³ximas 2 semanas)
1. **Implementar mejoras sugeridas** de alta prioridad
2. **Documentar cambios** en README y documentaciÃ³n tÃ©cnica
3. **Validar feedback visual** en todos los mÃ³dulos mejorados

### Mediano plazo (PrÃ³ximo mes)
1. **Automatizar verificaciones** mediante CI/CD
2. **Establecer mÃ©tricas de calidad** continuas
3. **Capacitar equipo** en nuevas herramientas y estÃ¡ndares

### Largo plazo (PrÃ³ximos 3 meses)
1. **Monitoreo continuo** de calidad y seguridad
2. **Refinamiento de procesos** basado en experiencia
3. **ExpansiÃ³n de herramientas** para nuevas necesidades

---

## Comandos Ãštiles

### Ejecutar verificaciones especÃ­ficas
```bash
# AnÃ¡lisis completo de mÃ³dulos
python scripts/verificacion/ejecutar_analisis_completo.py

# Generar checklists actualizados
python scripts/verificacion/generar_checklists_completados.py

# Mejorar feedback visual
python scripts/verificacion/mejorar_feedback_visual.py

# Ejecutar todos los tests
python -m pytest tests/ -v

# Verificar seguridad
python scripts/verificacion/analizar_seguridad_sql_codigo.py
```

### Restaurar backups si es necesario
```bash
# Restaurar mÃ³dulo especÃ­fico
cp backups_feedback/[modulo]_view_backup.py modules/[modulo]/view.py
```

---

## Notas Finales

Este informe fue generado automÃ¡ticamente el {fecha} por el sistema de verificaciÃ³n integral del proyecto.

**Contacto:** Para dudas sobre este informe o las herramientas utilizadas, consultar la documentaciÃ³n en `docs/` o revisar los scripts en `scripts/verificacion/`.

**Siguiente verificaciÃ³n recomendada:** {(datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d")} (en 7 dÃ­as)

---

*Generado por: Sistema de VerificaciÃ³n Integral v1.0*
"""

        # Guardar informe
        informe_file = self.proyecto_root / "informe_estado_proyecto.md"
        with open(informe_file, 'w', encoding='utf-8') as f:
            f.write(informe)

        print(f"âœ… Informe final generado: {informe_file}")

        # TambiÃ©n guardar datos JSON para procesamiento posterior
        json_file = self.proyecto_root / "tests/reports/estado_tests.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.estado_global, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š Datos JSON guardados: {json_file}")

    # Crear directorio de reportes si no existe
    os.makedirs("tests/reports", exist_ok=True)

def main():
    """FunciÃ³n principal del script."""
    script_dir = Path(__file__).parent
    proyecto_root = script_dir.parent.parent

    verificador = VerificadorCompleto(str(proyecto_root))
    verificador.ejecutar_verificacion_completa()

if __name__ == "__main__":
    main()
